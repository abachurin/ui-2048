import threading

from .game_mechanics import *
import numpy as np

WATCH = {
    'user name': {
        'agent': 'AgentLogic object',
        'moves': 'move sequence generated by AgentLogic object',
        'tiles': 'random tiles after moves'
    }
}


def f_2(x):
    x_vert = ((x[:3, :] << 4) + x[1:, :]).ravel()
    x_hor = ((x[:, :3] << 4) + x[:, 1:]).ravel()
    return np.concatenate([x_vert, x_hor])


def f_3(x):
    x_vert = ((x[:2, :] << 8) + (x[1:3, :] << 4) + x[2:, :]).ravel()
    x_hor = ((x[:, :2] << 8) + (x[:, 1:3] << 4) + x[:, 2:]).ravel()
    x_ex_00 = ((x[1:, :3] << 8) + (x[1:, 1:] << 4) + x[:3, 1:]).ravel()
    x_ex_01 = ((x[:3, :3] << 8) + (x[1:, :3] << 4) + x[1:, 1:]).ravel()
    x_ex_10 = ((x[:3, :3] << 8) + (x[:3, 1:] << 4) + x[1:, 1:]).ravel()
    x_ex_11 = ((x[:3, :3] << 8) + (x[1:, :3] << 4) + x[:3, 1:]).ravel()
    return np.concatenate([x_vert, x_hor, x_ex_00, x_ex_01, x_ex_10, x_ex_11])


def f_4(x):
    x_vert = ((x[0, :] << 12) + (x[1, :] << 8) + (x[2, :] << 4) + x[3, :]).ravel()
    x_hor = ((x[:, 0] << 12) + (x[:, 1] << 8) + (x[:, 2] << 4) + x[:, 3]).ravel()
    x_sq = ((x[:3, :3] << 12) + (x[1:, :3] << 8) + (x[:3, 1:] << 4) + x[1:, 1:]).ravel()
    return np.concatenate([x_vert, x_hor, x_sq])


# Finally, we try adding 4 "cross" 5-features for middle cells
def f_5(x):
    x_vert = ((x[0, :] << 12) + (x[1, :] << 8) + (x[2, :] << 4) + x[3, :]).ravel()
    x_hor = ((x[:, 0] << 12) + (x[:, 1] << 8) + (x[:, 2] << 4) + x[:, 3]).ravel()
    x_sq = ((x[:3, :3] << 12) + (x[1:, :3] << 8) + (x[:3, 1:] << 4) + x[1:, 1:]).ravel()
    x_middle = ((x[1: 3, 1: 3] << 16) + (x[:2, 1: 3] << 12) + (x[1: 3, :2] << 8) + (x[2:, 1: 3] << 4) + x[1: 3, 2:]
                ).ravel()
    return np.concatenate([x_vert, x_hor, x_sq, x_middle])


def f_6(x):
    x_vert = ((x[0, :] << 12) + (x[1, :] << 8) + (x[2, :] << 4) + x[3, :]).ravel()
    x_hor = ((x[:, 0] << 12) + (x[:, 1] << 8) + (x[:, 2] << 4) + x[:, 3]).ravel()
    x_sq = ((x[:3, :3] << 12) + (x[1:, :3] << 8) + (x[:3, 1:] << 4) + x[1:, 1:]).ravel()
    x_middle = ((x[1: 3, 1: 3] << 16) + (x[:2, 1: 3] << 12) + (x[1: 3, :2] << 8) + (x[2:, 1: 3] << 4) + x[1: 3, 2:]
                ).ravel()
    y = np.minimum(x, 13)
    x_vert_6 = (537824 * y[0: 2, 0: 3] + 38416 * y[1: 3, 0: 3] + 2744 * y[2:, 0: 3] + 196 * y[0: 2, 1:] +
                14 * y[1: 3, 1:] + y[2:, 1:]).ravel()
    x_hor_6 = (537824 * y[0: 3, 0: 2] + 38416 * y[0: 3, 1: 3] + 2744 * y[0: 3, 2:] + 196 * y[1:, 0: 2] +
               14 * y[1:, 1: 3] + y[1:, 2:]).ravel()
    return np.concatenate([x_vert, x_hor, x_sq, x_middle, x_vert_6, x_hor_6])


FEATURE_FUNCTIONS = {
    2: f_2,
    3: f_3,
    4: f_4,
    5: f_5,
    6: f_6
}


def random_eval(np_row, score):
    return random.random()


def score_eval(np_row, score):
    return score


class AgentLogic:

    def __init__(self, name: str, idx: str, n=None, np_weights=None):
        self.name = name
        self.idx = idx
        self.n = n
        self.w = None
        self.features = None
        match idx:
            case 'Random moves':
                self.eval = random_eval
            case 'Best score moves':
                self.eval = score_eval
            case _:
                self.w = []
                for weight_component in np_weights:
                    self.w += weight_component.tolist()
                del np_weights
                self.eval = self.evaluate
                self.features = FEATURE_FUNCTIONS[self.n]

    def evaluate(self, np_row, score=None):
        return sum([self.w[i][f] for i, f in enumerate(self.features(np_row))])

    @staticmethod
    def empty(x):
        return np.where(x == 0)

    @staticmethod
    def empty_count(x):
        return 16 - np.count_nonzero(x)

    @staticmethod
    def adjacent_pair_count(x):
        return 24 - np.count_nonzero(x[:, :3] - x[:, 1:]) - np.count_nonzero(x[:3, :] - x[1:, :])

    def game_over(self, x):
        if self.empty_count(x):
            return False
        return not self.adjacent_pair_count(x)

    def new_tile(self, x):
        i, j = self.empty(x)
        tile = 1 if random.randrange(10) else 2
        pos = random.randrange(len(i))
        x[i[pos], j[pos]] = tile
        return [i[pos], j[pos], tile]

    @staticmethod
    def _left(x, score):
        change = False
        new_x = x.copy()
        for i in range(4):
            line, line_score, change_line = GAME.table[tuple(x[i])]
            if change_line:
                change = True
                score += line_score
                new_x[i] = line
        return new_x, score, change

    def pre_move(self, x, score, direction):
        new_x = np.rot90(x, direction) if direction else x
        new_x, score, change = self._left(new_x, score)
        if direction:
            new_x = np.rot90(new_x, 4 - direction)
        return new_x, score, change

    def look_forward(self, x, score, depth, width, trigger):
        if depth == 0:
            return self.eval(x, score)
        empty = self.empty_count(x)
        if empty >= trigger:
            return self.eval(x, score)
        num_tiles = min(width, empty)
        empty_i, empty_j = self.empty(x)
        tile_positions = random.sample(range(len(empty_i)), num_tiles)
        average = 0
        for pos in tile_positions:
            new_tile = 1 if random.randrange(10) else 2
            new_x = x.copy()
            new_x[empty_i[pos], empty_j[pos]] = new_tile
            if self.game_over(new_x):
                best_value = 0
            else:
                best_value = - np.inf
                for direction in range(4):
                    test_x, test_score, change = self.pre_move(new_x, score, direction)
                    if change:
                        value = self.look_forward(test_x, test_score, depth=depth - 1, width=width, trigger=trigger)
                        best_value = max(best_value, value)
            average += max(best_value, 0)
        average = average / num_tiles
        return average

    def find_best_move(self, x, score, depth, width, trigger):
        best_dir, best_value = 0, - np.inf
        best_x, best_score = None, None
        for direction in range(4):
            new_x, new_score, change = self.pre_move(x, score, direction)
            if change:
                value = self.look_forward(new_x, new_score, depth=depth, width=width, trigger=trigger)
                if value > best_value:
                    best_dir, best_value = direction, value
                    best_x, best_score = new_x, new_score
        return best_dir, best_x, best_score

    def _run(self, params: dict, initial_game: dict):
        depth = params['depth']
        width = params['width']
        trigger = params['trigger']
        x = np.array(initial_game['row'], dtype=np.int32)
        score = initial_game['score']
        while not self.game_over(x):
            best_dir, x, score = self.find_best_move(x, score, depth, width, trigger)
            WATCH[self.name]['moves'].append(best_dir)
            WATCH[self.name]['tiles'].append(self.new_tile(x))

    def run(self, params: dict, initial_row: list):
        threading.Thread(target=self._run, args=(params, initial_row), daemon=True).start()


# a = AgentLogic('xxx', 'Best score moves')
# params = {
#     'depth': 2,
#     'width': 3,
#     'trigger': 5
# }
# initial_game = GAME.new_game()
#
# WATCH['xxx'] = {
#     'agent': a,
#     'moves': [],
#     'tiles': []
# }
#
# a._run(params, initial_game)
# for i in range(4):
#     print(i, len([v for v in WATCH['xxx']['moves'] if v == i]))
#
#
# y = input()